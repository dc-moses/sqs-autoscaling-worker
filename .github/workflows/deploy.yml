name: Deploy SQS Worker

on:
  push:
    branches: [ main ]
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

jobs:
  deploy:
    runs-on: ubuntu-latest
    env:
      LAMBDA_NAME: sqs-worker-lambda

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/github-ci-role
          aws-region: us-east-1

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: pip install boto3

      - name: Discover default subnet and write to env
        id: subnet
        run: |
          SUBNET_ID=$(aws ec2 describe-subnets --filters Name=default-for-az,Values=true --query "Subnets[0].SubnetId" --output text)
          echo "SUBNET_ID=$SUBNET_ID" >> $GITHUB_ENV
          echo "Discovered subnet: $SUBNET_ID"

      - name: Deploy CloudFormation stack
        run: |
          set +e
          python3 deploy.py
          STATUS=$?
          if [ $STATUS -ne 0 ]; then
            echo "‚ö†Ô∏è Deployment failed. Capturing logs..."
            aws cloudformation describe-stack-events --stack-name SQSWorkerStack \
              --query "StackEvents[?ResourceStatus=='ROLLBACK_COMPLETE'].[LogicalResourceId,ResourceStatusReason]" \
              --output table || echo "‚ö†Ô∏è Failed to fetch stack events."
          fi
          exit $STATUS

      - name: Deploy or Create Lambda function
        run: |
          zip lambda.zip lambda_trigger.py
          if aws lambda get-function --function-name $LAMBDA_NAME > /dev/null 2>&1; then
            aws lambda update-function-code \
              --function-name $LAMBDA_NAME \
              --zip-file fileb://lambda.zip
          else
            aws lambda create-function \
              --function-name $LAMBDA_NAME \
              --runtime python3.10 \
              --role arn:aws:iam::${{ secrets.AWS_ACCOUNT_ID }}:role/github-ci-role \
              --handler lambda_trigger.lambda_handler \
              --zip-file fileb://lambda.zip \
              --environment Variables="{QUEUE_URL=dummy-to-be-updated}"
          fi

      - name: Update Lambda environment with real queue URL
        run: |
          QUEUE_URL=$(aws cloudformation describe-stacks \
            --stack-name SQSWorkerStack \
            --query "Stacks[0].Outputs[?OutputKey=='SQSQueueURL'].OutputValue" \
            --output text)
          echo "Updating Lambda with QUEUE_URL=$QUEUE_URL"
          aws lambda update-function-configuration \
            --function-name $LAMBDA_NAME \
            --environment "{\"Variables\": {\"QUEUE_URL\": \"$QUEUE_URL\"}}"

      - name: Deploy API Gateway
        run: |
          sed -i "s/YourLambdaFunctionName/$LAMBDA_NAME/g" deploy_api_gateway.py
          python3 deploy_api_gateway.py

      - name: Send test job to SQS
        run: |
          QUEUE_URL=$(aws cloudformation describe-stacks \
            --stack-name SQSWorkerStack \
            --query "Stacks[0].Outputs[?OutputKey=='SQSQueueURL'].OutputValue" \
            --output text)
          echo "Sending test job to queue: $QUEUE_URL"
          aws sqs send-message --queue-url "$QUEUE_URL" --message-body '{"wait_seconds":10}'

      - name: Wait for ASG to scale up and down
        run: |
          ASG_NAME=$(aws cloudformation describe-stack-resources \
            --stack-name SQSWorkerStack \
            --query "StackResources[?ResourceType=='AWS::AutoScaling::AutoScalingGroup'].PhysicalResourceId" \
            --output text)

          echo "Polling ASG: $ASG_NAME for scale-up..."
          for i in {1..40}; do
            DESIRED=$(aws autoscaling describe-auto-scaling-groups \
              --auto-scaling-group-names "$ASG_NAME" \
              --query "AutoScalingGroups[0].DesiredCapacity" \
              --output text)

            INSTANCE_ID=$(aws autoscaling describe-auto-scaling-groups \
              --auto-scaling-group-names "$ASG_NAME" \
              --query "AutoScalingGroups[0].Instances[0].InstanceId" \
              --output text)

            if [ "$DESIRED" -ge 1 ] && [ "$INSTANCE_ID" != "None" ]; then
              echo "‚úÖ ASG scaled up with instance $INSTANCE_ID."
              break
            fi
            sleep 30
          done

          echo "Waiting for ASG to scale down to 0..."
          for i in {1..40}; do
            INSTANCE_COUNT=$(aws autoscaling describe-auto-scaling-groups \
              --auto-scaling-group-names "$ASG_NAME" \
              --query "length(AutoScalingGroups[0].Instances)" \
              --output text)

            echo "Poll $i: Current instance count = $INSTANCE_COUNT"
            if [ "$INSTANCE_COUNT" -eq 0 ]; then
              echo "‚úÖ EC2 instance has terminated and ASG scaled down to 0."
              break
            fi
            sleep 30
          done

      - name: Cleanup CloudFormation stack and S3 bucket
        if: always()
        run: |
          echo "üßπ Cleaning up CloudFormation stack and S3 bucket..."
          aws cloudformation delete-stack --stack-name SQSWorkerStack || true
          aws cloudformation wait stack-delete-complete --stack-name SQSWorkerStack || echo "‚ö†Ô∏è Stack deletion waiter timed out"

          BUCKET_NAME=$(aws s3api list-buckets --query "Buckets[?starts_with(Name, 'worker-bucket-')].Name" --output text | head -n1)
          if [ -n "$BUCKET_NAME" ]; then
            aws s3 rm s3://$BUCKET_NAME --recursive || true
            aws s3api delete-bucket --bucket $BUCKET_NAME || true
            echo "‚úÖ Bucket $BUCKET_NAME deleted."
          else
            echo "No matching worker bucket found."
          fi